{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "view-in-github",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mlnoobs/mlops-project-study/blob/main/2022-05-30/homework/cnrywjd11_mnist_inference.ipynb)\n",
        "\n",
        "# 딥러닝 remind 세미나 1 - 숙제: mnist inference 해보기\n",
        "anthony.go\n",
        "\n",
        "- 훈련된 모델 로드를 위해 아래 taylor의 노트북을 참고했습니다.\n",
        "  - https://github.com/mlnoobs/mlops-project-study/blob/main/2022-05-30/training_remind_seminar.ipynb\n",
        "- 훈련부터 인퍼런스 결과 확인까지 할 수 있도록 제작했습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 필요 툴&라이브러리 설치"
      ],
      "metadata": {
        "id": "_ck6yHmNfb7F"
      },
      "id": "_ck6yHmNfb7F"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install torch\n",
        "!pip install torchvision\n",
        "!pip install numpy\n",
        "!pip install matplotlib\n"
      ],
      "metadata": {
        "id": "kPHKc8y7fqMk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "832d366f-f84d-4892-c231-936655b3e66d"
      },
      "id": "kPHKc8y7fqMk",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n",
            "Collecting pip\n",
            "  Downloading pip-22.1.2-py3-none-any.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 8.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 21.1.3\n",
            "    Uninstalling pip-21.1.3:\n",
            "      Successfully uninstalled pip-21.1.3\n",
            "Successfully installed pip-22.1.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.2.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.12.0+cu113)\n",
            "Requirement already satisfied: torch==1.11.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.11.0+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchvision) (4.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2.10)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.21.6)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.4.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib) (4.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## import"
      ],
      "metadata": {
        "id": "N_XAZJXsgyY5"
      },
      "id": "N_XAZJXsgyY5"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from matplotlib import pyplot as plt\n",
        "import time\n"
      ],
      "metadata": {
        "id": "jEIP5rscg3ZD"
      },
      "id": "jEIP5rscg3ZD",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperpatemerers 등 configs 세팅"
      ],
      "metadata": {
        "id": "4t53bdHUjmDC"
      },
      "id": "4t53bdHUjmDC"
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 결과 재현을 위한 seed값 고정\n",
        "seed = '202205281708'\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "\n",
        "# Hyperparameters\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "lr = 1e-2\n",
        "n_epochs = 10\n",
        "batch_size = 512"
      ],
      "metadata": {
        "id": "bduUNYwgjtE0"
      },
      "id": "bduUNYwgjtE0",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 공개 데이터셋 다운로드: MNIST\n",
        "torchvision 라이브러리를 사용하면 공개 데이터셋을 편리하게 다운로드받고, torch tensor 자료형으로 불러올 수 있습니다."
      ],
      "metadata": {
        "id": "N6HFmHqphvVO"
      },
      "id": "N6HFmHqphvVO"
    },
    {
      "cell_type": "code",
      "source": [
        "# torchvision 라이브러리를 사용해 MNIST 데이터셋 다운로드 및 전처리\n",
        "transform = torchvision.transforms.Compose([\n",
        "                torchvision.transforms.ToTensor(),\n",
        "                torchvision.transforms.Normalize((0.1307,), (0.3081,)) # MNIST 데이터셋의 평균과 표준편차\n",
        "            ])\n",
        "train_data = torchvision.datasets.MNIST('./mnist_dataset', train=True, download=True,\n",
        "                            transform=transform)\n",
        "test_data = torchvision.datasets.MNIST('./mnist_dataset', train=False, download=True,\n",
        "                            transform=transform)\n",
        "print('len(train_data):', len(train_data))\n",
        "print('len(test_data):', len(test_data))\n",
        "\n",
        "# 데이터 정보를 확인해봅시다.\n",
        "sample = train_data[1234]\n",
        "print('shape:', sample[0].shape)   # 28*28 흑백 데이터\n",
        "print('label:', sample[1])\n",
        "print('maxval:', torch.max(sample[0]))\n",
        "print('minval:', torch.min(sample[0]))\n",
        "train_data_without_labels = torch.stack([s[0] for s in train_data])\n",
        "print('mean of all training dataset:', torch.mean(train_data_without_labels))\n",
        "print('var of all training dataset:', torch.var(train_data_without_labels))\n",
        "plt.imshow(sample[0][0])\n",
        "plt.show()\n",
        "\n",
        "# torch의 DataLoader를 사용하면 데이터셋을 준비하는 과정이 편리합니다.\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_data,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "# batchsize 1000->1로 변경하여 test_loader로 조회시 이미지 한장씩 가져옴\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_data,\n",
        "                                          batch_size=1,\n",
        "                                          shuffle=True)"
      ],
      "metadata": {
        "id": "zmt6BsoYiiQq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "outputId": "7fd5a4eb-fb3f-490f-befc-c2fd820008cc"
      },
      "id": "zmt6BsoYiiQq",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(train_data): 60000\n",
            "len(test_data): 10000\n",
            "shape: torch.Size([1, 28, 28])\n",
            "label: 3\n",
            "maxval: tensor(2.8215)\n",
            "minval: tensor(-0.4242)\n",
            "mean of all training dataset: tensor(-0.0001)\n",
            "var of all training dataset: tensor(1.0001)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 훈련 & 인퍼런스 테스트 코드 정의"
      ],
      "metadata": {
        "id": "N4ffWtEayY-t"
      },
      "id": "N4ffWtEayY-t"
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, device, train_loader, optimizer, n_epochs, fn_loss,\n",
        "                log_interval=10000):\n",
        "    model.train()\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = fn_loss(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            if batch_idx % (log_interval // len(data)) == 0:\n",
        "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                      epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                      100. * batch_idx / len(train_loader), loss.item()))\n",
        "            \n",
        "def test_model(model, device, data, target):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "        output = model(data)\n",
        "        #디멘젼을 유지 하지 않는다. 1차원으로 변경\n",
        "        pred = output.argmax(dim=1, keepdim=False)\n",
        "        print('\\n pred: ', pred)\n",
        "        print('\\n target: ', target)\n",
        "        #그림 그리기 위해선 numpy 타입이 필요해 cpu로 가져옴\n",
        "        plt.imshow(data[0][0].cpu().numpy())\n",
        "        plt.show()\n",
        "        \n",
        "        #결과값을 보기위해 cpu로 가져와서 numpy 타입으로 변경하고 [0]으로 값을 출력\n",
        "        print('\\n pred[0]: ', pred.cpu().numpy()[0])\n",
        "        print('\\n target[0]: ', target.cpu().numpy()[0])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "36NR-n81yb0l"
      },
      "id": "36NR-n81yb0l",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear layer 3개 학습\n"
      ],
      "metadata": {
        "id": "uezf4X4a5oHD"
      },
      "id": "uezf4X4a5oHD"
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelV2(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ModelV2, self).__init__()\n",
        "        self.input_size = 28*28\n",
        "        self.hidden_size = 256\n",
        "        self.output_size = 10\n",
        "        self.layers = torch.nn.Sequential(\n",
        "            torch.nn.Linear(self.input_size, self.hidden_size),\n",
        "            torch.nn.Linear(self.hidden_size, self.hidden_size),\n",
        "            torch.nn.Linear(self.hidden_size, self.output_size),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, self.input_size)\n",
        "        for idx, layer in enumerate(self.layers):\n",
        "            x = layer(x)\n",
        "            x = F.relu(x) if idx != len(self.layers)-1 else x\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output\n",
        "\n",
        "print(\"loading ModelV2...\") \n",
        "model = ModelV2().to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "fn_loss = F.nll_loss\n",
        "print(\"loaded ModelV2 to {}\".format(device))\n",
        "print(model)\n",
        "print('Number of model parameters: ', sum(param.numel() for param in model.parameters()))\n",
        "print(\"device:\", device)\n",
        "print(\"lr:\", lr)\n",
        "print(\"n_epochs:\", n_epochs)\n",
        "print(\"batch_size:\", batch_size)\n",
        "\n",
        "\n",
        "train_model(model, device, train_loader, optimizer, n_epochs, fn_loss, log_interval=60000)"
      ],
      "metadata": {
        "id": "hbXnlqCr5uYm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9181a069-4159-43ab-f17f-a472084da576"
      },
      "id": "hbXnlqCr5uYm",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading ModelV2...\n",
            "loaded ModelV2 to cuda\n",
            "ModelV2(\n",
            "  (layers): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=256, bias=True)\n",
            "    (1): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Number of model parameters:  269322\n",
            "device: cuda\n",
            "lr: 0.01\n",
            "n_epochs: 10\n",
            "batch_size: 512\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.312358\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 1.669297\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.814515\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.607452\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.454868\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.455215\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.390218\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.307778\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.336194\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.275993\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 인퍼런스 테스트"
      ],
      "metadata": {
        "id": "O1ll_Ww3MICV"
      },
      "id": "O1ll_Ww3MICV"
    },
    {
      "cell_type": "code",
      "source": [
        "# cnt: batchsize가 1인 상태에서 데이터 하나만 가져오기 위함\n",
        "cnt = 0\n",
        "for data, target in test_loader:\n",
        "    t = time.perf_counter()\n",
        "    test_model(model, device, data, target)\n",
        "    print(\"Eval done. elapsed: {} sec\".format(time.perf_counter() - t))\n",
        "    cnt += 1\n",
        "    if cnt == 10:\n",
        "      break\n",
        "\n",
        "# 모델 재학습 시키지 않기 위해\n",
        "# del model\n",
        "# del optimizer\n",
        "# torch.cuda.empty_cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "QxBWOJDYGTKE",
        "outputId": "997901b0-b898-453d-a5a4-8a229823d9b3"
      },
      "id": "QxBWOJDYGTKE",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " pred:  tensor([9], device='cuda:0')\n",
            "\n",
            " target:  tensor([9], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " pred[0]:  9\n",
            "\n",
            " target[0]:  9\n",
            "Eval done. elapsed: 0.11174757000026148 sec\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "colab": {
      "name": "cnrywjd11_mnist_inference.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
