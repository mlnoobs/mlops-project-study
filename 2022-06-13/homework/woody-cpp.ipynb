{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mlnoobs/mlops-project-study/blob/main/2022-06-13/homework/woody-cpp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12256fb1",
      "metadata": {
        "id": "12256fb1"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mlnoobs/mlops-project-study/blob/main/2022-05-30/training_remind_seminar.ipynb)\n",
        "\n",
        "# 딥러닝 remind 세미나 1\n",
        "taylor (2022-05-30)\n",
        "\n",
        "- Linear(Fully-Connected layer), CNN(Convolutional neural network) 훈련 및 인퍼런스를 PyTorch를 사용해 google colab GPU에서 시도합니다.\n",
        "- 노트북 제작에 있어 다음 레퍼런스를 많이 참고했습니다.\n",
        "  - https://github.com/espnet/notebook/blob/master/tts_realtime_demo.ipynb\n",
        "  - https://github.com/pytorch/examples/blob/main/mnist/main.py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 필요 툴&라이브러리 설치"
      ],
      "metadata": {
        "id": "_ck6yHmNfb7F"
      },
      "id": "_ck6yHmNfb7F"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install torch\n",
        "!pip install torchvision\n",
        "!pip install numpy\n",
        "!pip install matplotlib\n"
      ],
      "metadata": {
        "id": "kPHKc8y7fqMk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3180ccf-4d53-4c58-b228-d9e5bcf81257"
      },
      "id": "kPHKc8y7fqMk",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n",
            "Collecting pip\n",
            "  Downloading pip-22.1.2-py3-none-any.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 14.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 21.1.3\n",
            "    Uninstalling pip-21.1.3:\n",
            "      Successfully uninstalled pip-21.1.3\n",
            "Successfully installed pip-22.1.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.2.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.12.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchvision) (4.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision) (2.23.0)\n",
            "Requirement already satisfied: torch==1.11.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.11.0+cu113)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (3.0.4)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.21.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.4.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib) (4.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## import & 버전 확인"
      ],
      "metadata": {
        "id": "N_XAZJXsgyY5"
      },
      "id": "N_XAZJXsgyY5"
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version\n",
        "!nvidia-smi\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from matplotlib import pyplot as plt\n",
        "import time\n",
        "print(torch.__version__)\n",
        "print(np.__version__)\n",
        "print(torchvision.__version__)\n"
      ],
      "metadata": {
        "id": "jEIP5rscg3ZD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adc80ad0-c2d5-45b3-ed37-741a5bfd248b"
      },
      "id": "jEIP5rscg3ZD",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.13\n",
            "Mon Jun 13 08:14:55 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P8    11W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "1.11.0+cu113\n",
            "1.21.6\n",
            "0.12.0+cu113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperpatemerers 등 configs 세팅"
      ],
      "metadata": {
        "id": "4t53bdHUjmDC"
      },
      "id": "4t53bdHUjmDC"
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 결과 재현을 위한 seed값 고정\n",
        "seed = '202205281708'\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "\n",
        "# Hyperparameters\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "lr = 1e-2\n",
        "n_epochs = 10\n",
        "batch_size = 512\n",
        "\n",
        "print(\"device:\", device)\n",
        "print(\"- gpu를 사용할 수 있는 환경이면 \\'cuda\\', 그렇지 않으면 \\'cpu\\'를 사용합니다.\")\n",
        "print(\"lr:\", lr)\n",
        "print(\"- learning rate는 이번 훈련으로 얻어낸 gradients를 얼마만큼의 강도로 모델 업데이트에 반영할지를 결정합니다.\")\n",
        "print(\"n_epochs:\", n_epochs)\n",
        "print(\"- epoch의 횟수는 전체 데이터셋을 몇 번 반복해서 훈련할 것인지를 결정합니다.\")\n",
        "print(\"batch_size:\", batch_size)\n",
        "print(\"- 훈련 시 mini-batch의 사이즈를 결정합니다.\")\n",
        "print(\"- SGD(stochastic gradient descent) 기반의 optimizer를 사용한다면,\")\n",
        "print(\"- 전체 데이터셋을 자그마한 mini-batch로 나누어서 순차적으로 훈련에 사용하게 됩니다.\")\n",
        "print(\"- 보통 클수록 보다 성능을 높이는 방향으로 훈련될 가능성이 높지만 메모리를 많이 차지하게 됩니다.\")"
      ],
      "metadata": {
        "id": "bduUNYwgjtE0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "350a05c2-24d1-4ec5-d1ce-2da535a17071"
      },
      "id": "bduUNYwgjtE0",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cuda\n",
            "- gpu를 사용할 수 있는 환경이면 'cuda', 그렇지 않으면 'cpu'를 사용합니다.\n",
            "lr: 0.01\n",
            "- learning rate는 이번 훈련으로 얻어낸 gradients를 얼마만큼의 강도로 모델 업데이트에 반영할지를 결정합니다.\n",
            "n_epochs: 10\n",
            "- epoch의 횟수는 전체 데이터셋을 몇 번 반복해서 훈련할 것인지를 결정합니다.\n",
            "batch_size: 512\n",
            "- 훈련 시 mini-batch의 사이즈를 결정합니다.\n",
            "- SGD(stochastic gradient descent) 기반의 optimizer를 사용한다면,\n",
            "- 전체 데이터셋을 자그마한 mini-batch로 나누어서 순차적으로 훈련에 사용하게 됩니다.\n",
            "- 보통 클수록 보다 성능을 높이는 방향으로 훈련될 가능성이 높지만 메모리를 많이 차지하게 됩니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 공개 데이터셋 다운로드: MNIST\n",
        "torchvision 라이브러리를 사용하면 공개 데이터셋을 편리하게 다운로드받고, torch tensor 자료형으로 불러올 수 있습니다."
      ],
      "metadata": {
        "id": "N6HFmHqphvVO"
      },
      "id": "N6HFmHqphvVO"
    },
    {
      "cell_type": "code",
      "source": [
        "# torchvision 라이브러리를 사용해 MNIST 데이터셋 다운로드 및 전처리\n",
        "transform = torchvision.transforms.Compose([\n",
        "                torchvision.transforms.ToTensor(),\n",
        "                torchvision.transforms.Normalize((0.1307,), (0.3081,)) # MNIST 데이터셋의 평균과 표준편차\n",
        "            ])\n",
        "train_data = torchvision.datasets.MNIST('./mnist_dataset', train=True, download=True,\n",
        "                            transform=transform)\n",
        "test_data = torchvision.datasets.MNIST('./mnist_dataset', train=False, download=True,\n",
        "                            transform=transform)\n",
        "print('len(train_data):', len(train_data))\n",
        "print('len(test_data):', len(test_data))\n",
        "\n",
        "# 데이터 정보를 확인해봅시다.\n",
        "sample = train_data[1234]\n",
        "print('shape:', sample[0].shape)\n",
        "print('label:', sample[1])\n",
        "print('maxval:', torch.max(sample[0]))\n",
        "print('minval:', torch.min(sample[0]))\n",
        "train_data_without_labels = torch.stack([s[0] for s in train_data])\n",
        "print('mean of all training dataset:', torch.mean(train_data_without_labels))\n",
        "print('var of all training dataset:', torch.var(train_data_without_labels))\n",
        "plt.imshow(sample[0][0])\n",
        "plt.show()\n",
        "\n",
        "# torch의 DataLoader를 사용하면 데이터셋을 준비하는 과정이 편리합니다.\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_data,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_data,\n",
        "                                          batch_size=1000,\n",
        "                                          shuffle=True)"
      ],
      "metadata": {
        "id": "zmt6BsoYiiQq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "outputId": "5b094ab9-979f-42f0-d2a6-9ecbb343f16a"
      },
      "id": "zmt6BsoYiiQq",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(train_data): 60000\n",
            "len(test_data): 10000\n",
            "shape: torch.Size([1, 28, 28])\n",
            "label: 3\n",
            "maxval: tensor(2.8215)\n",
            "minval: tensor(-0.4242)\n",
            "mean of all training dataset: tensor(-0.0001)\n",
            "var of all training dataset: tensor(1.0001)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##훈련 & 테스트 코드"
      ],
      "metadata": {
        "id": "fVoCk22BI3RC"
      },
      "id": "fVoCk22BI3RC"
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, device, train_loader, optimizer, n_epochs, fn_loss,\n",
        "                log_interval=10000):\n",
        "    model.train()\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = fn_loss(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            if batch_idx % (log_interval // len(data)) == 0:\n",
        "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                      epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                      100. * batch_idx / len(train_loader), loss.item()))\n",
        "            \n",
        "def test_model(model, device, test_loader, fn_loss):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "metadata": {
        "id": "clGb6BSlI4ki"
      },
      "id": "clGb6BSlI4ki",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear layer 3개"
      ],
      "metadata": {
        "id": "uezf4X4a5oHD"
      },
      "id": "uezf4X4a5oHD"
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelV2(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ModelV2, self).__init__()\n",
        "        self.input_size = 28*28\n",
        "        self.hidden_size = 256\n",
        "        self.output_size = 10\n",
        "        self.layers = torch.nn.Sequential(\n",
        "            torch.nn.Linear(self.input_size, self.hidden_size),\n",
        "            torch.nn.Linear(self.hidden_size, self.hidden_size),\n",
        "            torch.nn.Linear(self.hidden_size, self.output_size),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, self.input_size)\n",
        "        for idx, layer in enumerate(self.layers):\n",
        "            x = layer(x)\n",
        "            x = F.relu(x) if idx != len(self.layers)-1 else x\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output\n",
        "\n",
        "print(\"loading ModelV2...\") \n",
        "model = ModelV2().to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "fn_loss = F.nll_loss\n",
        "print(\"loaded ModelV2 to {}\".format(device))\n",
        "print(model)\n",
        "print('Number of model parameters: ', sum(param.numel() for param in model.parameters()))\n",
        "print(\"device:\", device)\n",
        "print(\"lr:\", lr)\n",
        "print(\"n_epochs:\", n_epochs)\n",
        "print(\"batch_size:\", batch_size)\n",
        "\n",
        "t = time.perf_counter()\n",
        "train_model(model, device, train_loader, optimizer, n_epochs, fn_loss, log_interval=60000)\n",
        "test_model(model, device, test_loader, fn_loss)\n",
        "print(\"Train/Eval done. elapsed: {} sec\".format(time.perf_counter() - t))"
      ],
      "metadata": {
        "id": "hbXnlqCr5uYm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "670aa589-3cd3-4603-f639-ff44cf158421"
      },
      "id": "hbXnlqCr5uYm",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading ModelV2...\n",
            "loaded ModelV2 to cuda\n",
            "ModelV2(\n",
            "  (layers): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=256, bias=True)\n",
            "    (1): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Number of model parameters:  269322\n",
            "device: cuda\n",
            "lr: 0.01\n",
            "n_epochs: 10\n",
            "batch_size: 512\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.297972\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 1.591278\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.820197\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.527010\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.436903\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.412355\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.409548\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.355316\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.280423\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.340139\n",
            "\n",
            "Test set: Average loss: 0.2988, Accuracy: 9152/10000 (92%)\n",
            "\n",
            "Train/Eval done. elapsed: 90.101525939 sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##숙제"
      ],
      "metadata": {
        "id": "f-MfHdYueJhk"
      },
      "id": "f-MfHdYueJhk"
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"./model.pt\")\n",
        "del model\n",
        "del optimizer\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "UsP7oMIyjUAV"
      },
      "id": "UsP7oMIyjUAV",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cpu')\n",
        "model = ModelV2()\n",
        "model.load_state_dict(torch.load(\"./model.pt\", map_location=device))\n",
        "\n",
        "#model.eval()\n",
        "\n",
        "test_data = torchvision.datasets.MNIST('./mnist_dataset', train=False, download=True,\n",
        "                            transform=transform)\n",
        "\n",
        "test_num = 99\n",
        "\n",
        "plt.imshow(test_data.data[test_num])\n",
        "\n",
        "x = test_data.data[test_num]\n",
        "x = x.type(torch.float)\n",
        "\n",
        "t = time.perf_counter()\n",
        "output = model(x)\n",
        "result = output.argmax(dim=1, keepdim=False)\n",
        "print(\"inference elapsed: {} sec\".format(time.perf_counter() - t))\n",
        "print(\"result :\", result.item())\n",
        "print(\"expect :\", test_data.targets[test_num].item())\n",
        "print(\"ok\" if result.item() == test_data.targets[test_num].item() else \"failed\")\n",
        "\n",
        "output = 0\n",
        "result = 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "W7kpYbd5eMkF",
        "outputId": "f1e0d9d0-e3b1-49ef-a4ea-c30d281ba24f"
      },
      "id": "W7kpYbd5eMkF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inference elapsed: 0.00047270599998228136 sec\n",
            "result : 9\n",
            "expect : 9\n",
            "ok\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Inference**"
      ],
      "metadata": {
        "id": "PIEMIO9oD6ii"
      },
      "id": "PIEMIO9oD6ii"
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image # pillow install\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "class Mnist():\n",
        "  def __init__(self, model_path, device):\n",
        "    self.device = torch.device(device)\n",
        "    self.model = ModelV2()\n",
        "    self.model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    self.model.eval()\n",
        "\n",
        "  def preprocess(self, image_path):\n",
        "    image = Image.open(image_path)\n",
        "    image_gray = image.convert('L')\n",
        "    image_resize = image_gray.resize((28,28))\n",
        "    return image_resize\n",
        "\n",
        "  def process(self, image):\n",
        "    t = time.perf_counter()\n",
        "    # 색반전\n",
        "    # image = np.invert(image)\n",
        "    plt.imshow(image)\n",
        "\n",
        "    processed_image = np.array(image)\n",
        "    tensor_image = torch.from_numpy(processed_image)\n",
        "\n",
        "    x = tensor_image.type(torch.float)\n",
        "    with torch.no_grad():\n",
        "      output = self.model(x)\n",
        "      result = output.argmax(dim=1, keepdim=False)\n",
        "    print(\"inference elapsed: {} sec\".format(time.perf_counter() - t))\n",
        "    return result.item()\n",
        "\n",
        "url = 'http://img1.tmon.kr/cdn4/deals/2021/12/16/9274000174/front_a396e_d8rmi.jpg'\n",
        "os.system(\"curl \" + url + \" > test.jpg\")\n",
        "\n",
        "inference = Mnist(\"./model.pt\", 'cpu')\n",
        "\n",
        "processed_img = inference.preprocess('./test.jpg')\n",
        "result = inference.process(processed_img)\n",
        "\n",
        "print(\"result :\", result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "OcyjARGbD9jo",
        "outputId": "8227b479-5b5c-4748-c9df-970f00325671"
      },
      "id": "OcyjARGbD9jo",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inference elapsed: 0.014780860999962897 sec\n",
            "result : 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAQ9ElEQVR4nO3dfZBV9XkH8O+XXZb3EpYFssIqLy6MSADjhmZGQ0hsQemkwKSlUseSqck6VVrTJBpr2gHTZuokUavVMa4CYlUYp2CkLS0iyZSojbAQ3okLIgQIsguovMnLLk//2ENmgT3Pud733d/3M7NzL+e555zHK1/O3fs75/xoZhCRzq9LoRsQkfxQ2EUCobCLBEJhFwmEwi4SiNJ87qyivMSGVnXN5y5FgrJn3zkcPtrC9moZhZ3kzQAeA1AC4Fkze8h7/dCqrli7siqTXYqIY8KUfbG1tD/GkywB8CSAWwCMBjCL5Oh0tyciuZXJ7+wTAOwys91mdhbAEgDTstOWiGRbJmEfDKDtZ4b90bKLkKwlWU+yvulISwa7E5FM5PzbeDOrM7MaM6sZ0L8k17sTkRiZhP0AgLbftg2JlolIEcok7OsAVJMcRrIMwK0AlmenLRHJtrSH3sysmeQcACvROvS2wMy2Za0zEcmqjMbZzWwFgBVZ6kVEckiny4oEQmEXCYTCLhIIhV0kEAq7SCAUdpFA5PV6dknPOfOvKVh6oiK2tvzweHfdG/rtcuv9S0649TXHRrn1r5avi63d1EPXSuSTjuwigVDYRQKhsIsEQmEXCYTCLhIIhV0kEBp6y4NT58+69XFrat36lc/6d/jptnlPbK155BB33Se/ddmdxC7So5vf+8C/848XDx/sGVubO6naXffjr33g1td+dolbL6GOZW3p3RAJhMIuEgiFXSQQCrtIIBR2kUAo7CKBUNhFAqFx9iz4oOWUW//yQ99x68OffMutlw67yq2XLI2fBvvlEU+76/bu0t2tJ2n4r5Nufcrr98TWRt7xtrtur6X+vq//6zlu/bX7fhRbG1jSy994J6Qju0ggFHaRQCjsIoFQ2EUCobCLBEJhFwmEwi4SCJpZ3nZWM667rV1Zlbf95cvwVX/p1qtnb/A30MW/Xh2rKt3yymv+01+/SF1Td5dbv3Kef/5Bkp2P/35sbfef+OcfdFQTpuxD/abTbK+W0Uk1JPcAOA6gBUCzmdVksj0RyZ1snEH3JTM7nIXtiEgO6Xd2kUBkGnYD8BrJ9STbvZEayVqS9STrm45ouh+RQsn0Y/yNZnaA5EAAq0j+2szWtH2BmdUBqANav6DLcH8ikqaMjuxmdiB6bATwCoAJ2WhKRLIv7bCT7EWyz4XnACYD2JqtxkQkuzL5GD8IwCskL2znJTP7n6x0VYS8e78PW9TusGbKSkYNd+vzqxcmbKF3RvsvlIlTf+XW9zyY8L4mnCMyclH8dNOHZ/jX4Vd0wuvd0w67me0GMC6LvYhIDmnoTSQQCrtIIBR2kUAo7CKBUNhFAqFbSadox7n4WveG9911mxO23VzuD/NUlPRI2ELHNLb3fre+t+wKt25nzrj1kt8eia29c85/TysSrjruiHRkFwmEwi4SCIVdJBAKu0ggFHaRQCjsIoFQ2EUCoXH2IlDacMCtLz/Zz61/tfexbLaTNwfO+P9ddjb+suJUWL/fi61dVepPs91RLxv26MguEgiFXSQQCrtIIBR2kUAo7CKBUNhFAqGwiwRC4+wpGlMWf1vjk5/xr7vutt8fR29panLrD/3zbW79C9//cWxtYBHfEnnJFn/S32pLmOo6wXszK2JrQ0o73zh6Eh3ZRQKhsIsEQmEXCYTCLhIIhV0kEAq7SCAUdpFAaJw9Rd3YNbZ27p74+5MDQLf/zmzf5Qv/z63POPGt2Nr0ua+7695b/m5aPaWq4Vz81MjVTzg340/BmVs+59YXz37UqXbLaN8dUeKRneQCko0kt7ZZVk5yFcmd0aN/FwIRKbhUPsY/B+DmS5bdD2C1mVUDWB39WUSKWGLYzWwNgKOXLJ4GYFH0fBGA6VnuS0SyLN0v6AaZ2cHo+fsABsW9kGQtyXqS9U1HWtLcnYhkKuNv483MAJhTrzOzGjOrGdC/E86WJ9JBpBv2QyQrASB6bMxeSyKSC+mGfTmA2dHz2QBezU47IpIrbP0U7ryAXAxgEoAKAIcAzAXwUwAvA7gSwF4AM83s0i/xLlMzrrutXVmVYcsdz/Cld7r16r9Z628g4f+Rp6Siv1vf9Z2Rbv3ZmU+59Ynd/f1f9093xdYqX9gaWwOAvXPGuPXFtY+49bFlCc11QhOm7EP9ptPt3nwh8aQaM5sVU7opo65EJK90uqxIIBR2kUAo7CKBUNhFAqGwiwQicegtm0Ideksy4Vd/6tYr7o2/jTUAtGxvyGY7FympHu7WG2pjz5QGAPSs/jC29v1r/8Ndd3qvE25dLucNvenILhIIhV0kEAq7SCAUdpFAKOwigVDYRQKhsIsEQuPsHcCbp8+79a8/Nye2Nuzxbe66LR9+lFZPqSodPjS2tvPrle66T8x81q1P7pnZrag7I42zi4jCLhIKhV0kEAq7SCAUdpFAKOwigVDYRQKhcfYi8KVt09z66YX+ePRVd8dfz359373uuoufnOzWBzydcJvr87mb0qtk1NVu/aPH/PMP3hy7LJvtdAgaZxcRhV0kFAq7SCAUdpFAKOwigVDYRQKhsIsEInEWV0l2sNm/v/nkf73PrV/xo7fceo9rytz6Vyo2xdZu63PEXffef/CnZJ5+6xS3fvzBIW699Gfr3bqn5Z1dbr3PV/z3ZdQLfxFbe+cLz6fVU0eWeGQnuYBkI8mtbZbNI3mA5MboZ2pu2xSRTKXyMf45ADe3s/xRMxsf/azIblsikm2JYTezNQCO5qEXEcmhTL6gm0Nyc/Qxv1/ci0jWkqwnWd90JHfnUYuIL92wPwVgBIDxAA4CeDjuhWZWZ2Y1ZlYzoH9JmrsTkUylFXYzO2RmLWZ2HsAzACZkty0Ryba0wk6y7TWXMwBsjXutiBSHxHF2kosBTAJQQXI/gLkAJpEcD8AA7AFwZw57LApnLP4e5VN/mDCO/oQ/jg7686+X/uS4W08aS8/ET6tXuvXfPOefY/AHL94bWxv2vcyulbdzZ936iG/sia09+IvR7rpzB2x36x1RYtjNbFY7i+fnoBcRySGdLisSCIVdJBAKu0ggFHaRQCjsIoHQJa4pumnLn8XWBiYNrSX53Bi3/NKIZxI20D2z/WfgytLebr1hdvwltCOHxV+CCgDDb/+1W08aems5diy2tmzhJHfdufd1vqE3HdlFAqGwiwRCYRcJhMIuEgiFXSQQCrtIIBR2kUBonD1FZ5cMiq31wu6Mtt10vT9W3btL4cbRc6lhon8759H33eXWq36Q/vkNn37Lv2z4o/Mfu/W+XXqkve9C0ZFdJBAKu0ggFHaRQCjsIoFQ2EUCobCLBEJhFwmExtkjp87710Z/quFU7vZdmfyaEE2avsGtv/uD9Lfd5VT8rcEB4FTCbaz7dsDDZAdsWUTSobCLBEJhFwmEwi4SCIVdJBAKu0ggFHaRQGicPdKVJW7dusb/u+hPuJysy5lMt9A5fdzSNeEVp9PfdlUftz6wpGfa2y5WiUd2klUkf05yO8ltJO+JlpeTXEVyZ/TYL/ftiki6UvkY3wzg22Y2GsDnAdxNcjSA+wGsNrNqAKujP4tIkUoMu5kdNLMN0fPjAHYAGAxgGoBF0csWAZieqyZFJHOf6As6kkMBXAfgbQCDzOxgVHofQLs3aSNZS7KeZH3TEf98YxHJnZTDTrI3gKUAvmlmF82YZ2YGwNpbz8zqzKzGzGoG9Pe/BBOR3Ekp7CS7ojXoL5rZsmjxIZKVUb0SQGNuWhSRbEgceiNJAPMB7DCzR9qUlgOYDeCh6PHVnHSYJ0lDb43j428d/On/zWzfg+oTph628269hJ3zdIlfvHGtWx+BX6a97b1/7A93dsb3NJVx9hsA3A5gC8mN0bIH0Bryl0neAWAvgJm5aVFEsiEx7Gb2BuLPG7kpu+2ISK50vs8qItIuhV0kEAq7SCAUdpFAKOwigdAlrin64u3rYms7n/anVD5/2r8Us9vqjW79hk3+qOYvx/+7Wy9Wf9/4Gbc+6tHfuPXmhO03f/n62NqKW/4lYe0AL3EVkc5BYRcJhMIuEgiFXSQQCrtIIBR2kUAo7CKB0Dh7ih6/In6cfeTC2e66V//VHrfe8uFHbr38tiNufcz822Jrq2qedtetLO3t1pOupV9/1r/V2Kw3a2Nro/52v7/vpt+69eO3ft6t3/+Pz8fWrinrfOPoSXRkFwmEwi4SCIVdJBAKu0ggFHaRQCjsIoFQ2EUCwdbJXPKjZlx3W7uyKm/7KxZzm/z7ny974YtuvWqFP85+vuG92Bqvvdpd970H/Pvll5X5V40P+e45t86TH8fWjkxK+Lvw54fd8s/GvuTWe3Yp87ffCU2Ysg/1m063ezdoHdlFAqGwiwRCYRcJhMIuEgiFXSQQCrtIIBR2kUAkjrOTrALwPIBBAAxAnZk9RnIegG8AaIpe+oCZrfC2Feo4e6b2N59w6ytOjoytrfkgvgYAE/s1uPXBXY+69fqTw936jL4bYmtjy/z77csn542zp3LzimYA3zazDST7AFhPclVUe9TMfpytRkUkd1KZn/0ggIPR8+MkdwAYnOvGRCS7PtHv7CSHArgOwNvRojkkN5NcQLJfzDq1JOtJ1jcd8W9hJCK5k3LYSfYGsBTAN83sGICnAIwAMB6tR/6H21vPzOrMrMbMagb098/DFpHcSSnsJLuiNegvmtkyADCzQ2bWYmbnATwDYELu2hSRTCWGnSQBzAeww8weabO8ss3LZgDYmv32RCRbUvk2/gYAtwPYQvLC3MIPAJhFcjxah+P2ALgzJx0KhiTc7rm2b/wtl71aNvxRz+0Jr9DwWrFI5dv4NwC0N27njqmLSHHRGXQigVDYRQKhsIsEQmEXCYTCLhIIhV0kEAq7SCAUdpFAKOwigVDYRQKhsIsEQmEXCYTCLhIIhV0kEHmdsplkE4C9bRZVAPDn5S2cYu2tWPsC1Fu6stnbVWY2oL1CXsN+2c7JejOrKVgDjmLtrVj7AtRbuvLVmz7GiwRCYRcJRKHDXlfg/XuKtbdi7QtQb+nKS28F/Z1dRPKn0Ed2EckThV0kEAUJO8mbSb5DchfJ+wvRQxySe0huIbmRZH2Be1lAspHk1jbLykmuIrkzemx3jr0C9TaP5IHovdtIcmqBeqsi+XOS20luI3lPtLyg753TV17et7z/zk6yBEADgD8EsB/AOgCzzCxptoG8ILkHQI2ZFfwEDJITAZwA8LyZjYmW/RDAUTN7KPqHsp+ZfbdIepsH4EShp/GOZiuqbDvNOIDpAL6GAr53Tl8zkYf3rRBH9gkAdpnZbjM7C2AJgGkF6KPomdkaAEcvWTwNwKLo+SK0/mXJu5jeioKZHTSzDdHz4wAuTDNe0PfO6SsvChH2wQD2tfnzfhTXfO8G4DWS60nWFrqZdgwys4PR8/cBDCpkM+1InMY7ny6ZZrxo3rt0pj/PlL6gu9yNZvZZALcAuDv6uFqUrPV3sGIaO01pGu98aWea8d8p5HuX7vTnmSpE2A8AqGrz5yHRsqJgZgeix0YAr6D4pqI+dGEG3eixscD9/E4xTePd3jTjKIL3rpDTnxci7OsAVJMcRrIMwK0Alhegj8uQ7BV9cQKSvQBMRvFNRb0cwOzo+WwArxawl4sUyzTecdOMo8DvXcGnPzezvP8AmIrWb+TfBfC9QvQQ09dwAJuin22F7g3AYrR+rDuH1u827gDQH8BqADsBvA6gvIh6+zcAWwBsRmuwKgvU241o/Yi+GcDG6Gdqod87p6+8vG86XVYkEPqCTiQQCrtIIBR2kUAo7CKBUNhFAqGwiwRCYRcJxP8DmUcGjirWj1IAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "colab": {
      "name": "training_remind_seminar.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}