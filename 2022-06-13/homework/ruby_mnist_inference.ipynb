{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "_ck6yHmNfb7F",
   "metadata": {
    "id": "_ck6yHmNfb7F"
   },
   "source": [
    "## 필요 툴&라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "kPHKc8y7fqMk",
   "metadata": {
    "id": "kPHKc8y7fqMk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/ruby/opt/anaconda3/lib/python3.8/site-packages (22.1.2)\n",
      "Requirement already satisfied: torch in /Users/ruby/opt/anaconda3/lib/python3.8/site-packages (1.11.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/ruby/opt/anaconda3/lib/python3.8/site-packages (from torch) (4.0.1)\n",
      "Requirement already satisfied: torchvision in /Users/ruby/opt/anaconda3/lib/python3.8/site-packages (0.12.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/ruby/opt/anaconda3/lib/python3.8/site-packages (from torchvision) (8.2.0)\n",
      "Requirement already satisfied: torch==1.11.0 in /Users/ruby/opt/anaconda3/lib/python3.8/site-packages (from torchvision) (1.11.0)\n",
      "Requirement already satisfied: requests in /Users/ruby/opt/anaconda3/lib/python3.8/site-packages (from torchvision) (2.25.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/ruby/opt/anaconda3/lib/python3.8/site-packages (from torchvision) (4.0.1)\n",
      "Requirement already satisfied: numpy in /Users/ruby/opt/anaconda3/lib/python3.8/site-packages (from torchvision) (1.20.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/ruby/opt/anaconda3/lib/python3.8/site-packages (from requests->torchvision) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/ruby/opt/anaconda3/lib/python3.8/site-packages (from requests->torchvision) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/ruby/opt/anaconda3/lib/python3.8/site-packages (from requests->torchvision) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ruby/opt/anaconda3/lib/python3.8/site-packages (from requests->torchvision) (2020.12.5)\n",
      "Requirement already satisfied: numpy in /Users/ruby/opt/anaconda3/lib/python3.8/site-packages (1.20.1)\n",
      "Requirement already satisfied: matplotlib in /Users/ruby/opt/anaconda3/lib/python3.8/site-packages (3.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/ruby/opt/anaconda3/lib/python3.8/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/ruby/opt/anaconda3/lib/python3.8/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/ruby/opt/anaconda3/lib/python3.8/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/ruby/opt/anaconda3/lib/python3.8/site-packages (from matplotlib) (8.2.0)\n",
      "Requirement already satisfied: numpy>=1.15 in /Users/ruby/opt/anaconda3/lib/python3.8/site-packages (from matplotlib) (1.20.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /Users/ruby/opt/anaconda3/lib/python3.8/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: six in /Users/ruby/opt/anaconda3/lib/python3.8/site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
      "Requirement already satisfied: opencv-python in /Users/ruby/opt/anaconda3/lib/python3.8/site-packages (4.5.5.64)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /Users/ruby/opt/anaconda3/lib/python3.8/site-packages (from opencv-python) (1.20.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install torch\n",
    "!pip install torchvision\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "N_XAZJXsgyY5",
   "metadata": {
    "id": "N_XAZJXsgyY5"
   },
   "source": [
    "## import & 버전 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "jEIP5rscg3ZD",
   "metadata": {
    "id": "jEIP5rscg3ZD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.8\n",
      "zsh:1: command not found: nvidia-smi\n",
      "1.11.0\n",
      "1.20.1\n",
      "0.12.0\n"
     ]
    }
   ],
   "source": [
    "!python --version\n",
    "!nvidia-smi\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "print(torch.__version__)\n",
    "print(np.__version__)\n",
    "print(torchvision.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4t53bdHUjmDC",
   "metadata": {
    "id": "4t53bdHUjmDC"
   },
   "source": [
    "## inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bduUNYwgjtE0",
   "metadata": {
    "id": "bduUNYwgjtE0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class ModelV3(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelV3, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = torch.nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = torch.nn.Dropout(0.25)\n",
    "        self.dropout2 = torch.nn.Dropout(0.5)\n",
    "        self.fc1 = torch.nn.Linear(9216, 128)\n",
    "        self.fc2 = torch.nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "class inference_model:\n",
    "    def __init__(self):\n",
    "        self.model = torch.load('../model.pt')\n",
    "        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        #self.imgs = np.load('../mnist_inputs.npy')\n",
    "\n",
    "    def inference(self, img):\n",
    "        self.model = self.model.to(self.device)\n",
    "        \n",
    "        img = torch.from_numpy(img).float() # torch.tensor(random).float() ? 뭔 차이? 둘다 type은 tenser\n",
    "        img = img.to(self.device)\n",
    "\n",
    "        self.model.eval()    #nn.Module에서 train time과 eval time에서 수행하는 다른 작업을 수행할 수 있도록 switching 하는 함수\n",
    "        with torch.no_grad():\n",
    "            out = self.model(img)\n",
    "            label_idx = torch.argmax(out, dim=1)\n",
    "        return label_idx\n",
    "    \n",
    "\"\"\"\n",
    "MNIST의 test data 중에서 0부터 9까지 각 1장씩, 총 10장을 랜덤으로 추출해서 \n",
    "[10, 28, 28]의 shape로 묶어서 numpy.array 형태로 저장해둔 파일\n",
    "len(imgdata) = 10, len(imgdata[0]) = 28\n",
    "\"\"\"\n",
    "\n",
    "# print(imgdata[1].shape) (28,28) \n",
    "\n",
    "imgdata = np.load('../mnist_inputs.npy')\n",
    "\n",
    "for i in range(len(imgdata)):\n",
    "    testimg = np.expand_dims(imgdata[i], axis=(0,1)) # (28,28) -> (1, 1, 28, 28) 튜플을 사용해서 차원 한꺼번에 추가\n",
    "    #print(testimg.shape)\n",
    "    infer = inference_model()\n",
    "    rst = infer.inference(testimg).item()\n",
    "    print(rst)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51c0b2f",
   "metadata": {},
   "source": [
    "## inference 2\n",
    "- img 입력을 init 에서 & 결과 출력하는 함수를 inference model class의 메소드로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2654e3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class ModelV3(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelV3, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = torch.nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = torch.nn.Dropout(0.25)\n",
    "        self.dropout2 = torch.nn.Dropout(0.5)\n",
    "        self.fc1 = torch.nn.Linear(9216, 128)\n",
    "        self.fc2 = torch.nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "class inference_model:\n",
    "    def __init__(self):\n",
    "        self.model = torch.load('../model.pt')\n",
    "        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        self.imgs = np.load('../mnist_inputs.npy')\n",
    "    \n",
    "    def printInference(self):\n",
    "        for i in range(len(self.imgs)):\n",
    "            testimg = np.expand_dims(imgdata[i], axis=(0,1))\n",
    "            rst = self.inference(testimg)\n",
    "            print(rst.item())\n",
    "        return\n",
    "\n",
    "    def inference(self,img):\n",
    "        self.model = self.model.to(self.device)\n",
    "        \n",
    "        img = torch.from_numpy(img).float()\n",
    "        img = img.to(self.device)\n",
    "\n",
    "        self.model.eval()    \n",
    "        with torch.no_grad():\n",
    "            out = self.model(img)\n",
    "            label_idx = torch.argmax(out, dim=1)\n",
    "        return label_idx\n",
    "    \n",
    "\n",
    "infer = inference_model()\n",
    "infer.printInference()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "31da1cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "class ModelV3(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelV3, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = torch.nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = torch.nn.Dropout(0.25)\n",
    "        self.dropout2 = torch.nn.Dropout(0.5)\n",
    "        self.fc1 = torch.nn.Linear(9216, 128)\n",
    "        self.fc2 = torch.nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "class inference_model:\n",
    "    def __init__(self, img):\n",
    "        self.model = torch.load('../model.pt')\n",
    "        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        self.img = self.resize_img(img)\n",
    "\n",
    "    def inference(self):\n",
    "        self.model = self.model.to(self.device)\n",
    "        \n",
    "        #print(self.img)\n",
    "        \n",
    "        self.img = torch.from_numpy(self.img).float() # torch.tensor(random).float() ? 뭔 차이? 둘다 type은 tensor\n",
    "        self.img = self.img.to(self.device)\n",
    "\n",
    "        self.model.eval()    #nn.Module에서 train time과 eval time에서 수행하는 다른 작업을 수행할 수 있도록 switching 하는 함수\n",
    "        with torch.no_grad():\n",
    "            out = self.model(self.img)\n",
    "            label_idx = torch.argmax(out, dim=1)\n",
    "            mnist_rst = label_idx.item()\n",
    "        return mnist_rst\n",
    "    \n",
    "    def resize_img(self, img):\n",
    "        gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        resize_img = cv2.resize(gray_image, dsize=(28, 28), interpolation=cv2.INTER_CUBIC) #interpolation = 보간법\n",
    "        resize_img = torch.from_numpy(resize_img).float()\n",
    "        test_img = np.expand_dims(resize_img, axis=(0,1))\n",
    "        \n",
    "        return test_img\n",
    "\n",
    "    \n",
    "img = cv2.imread('seven.png')\n",
    "plt.imshow(img)\n",
    "\n",
    "infer = inference_model(img)\n",
    "mnist_rst = infer.inference()\n",
    "\n",
    "print(mnist_rst)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "training_remind_seminar.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
