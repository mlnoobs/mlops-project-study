{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "_ck6yHmNfb7F",
   "metadata": {
    "id": "_ck6yHmNfb7F"
   },
   "source": [
    "## 필요 툴&라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "kPHKc8y7fqMk",
   "metadata": {
    "id": "kPHKc8y7fqMk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/ruby/opt/anaconda3/lib/python3.8/site-packages (22.1.2)\n",
      "Requirement already satisfied: torch in /Users/ruby/opt/anaconda3/lib/python3.8/site-packages (1.11.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/ruby/opt/anaconda3/lib/python3.8/site-packages (from torch) (4.0.1)\n",
      "Requirement already satisfied: torchvision in /Users/ruby/opt/anaconda3/lib/python3.8/site-packages (0.12.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/ruby/opt/anaconda3/lib/python3.8/site-packages (from torchvision) (8.2.0)\n",
      "Requirement already satisfied: torch==1.11.0 in /Users/ruby/opt/anaconda3/lib/python3.8/site-packages (from torchvision) (1.11.0)\n",
      "Requirement already satisfied: requests in /Users/ruby/opt/anaconda3/lib/python3.8/site-packages (from torchvision) (2.25.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/ruby/opt/anaconda3/lib/python3.8/site-packages (from torchvision) (4.0.1)\n",
      "Requirement already satisfied: numpy in /Users/ruby/opt/anaconda3/lib/python3.8/site-packages (from torchvision) (1.20.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/ruby/opt/anaconda3/lib/python3.8/site-packages (from requests->torchvision) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/ruby/opt/anaconda3/lib/python3.8/site-packages (from requests->torchvision) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/ruby/opt/anaconda3/lib/python3.8/site-packages (from requests->torchvision) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ruby/opt/anaconda3/lib/python3.8/site-packages (from requests->torchvision) (2020.12.5)\n",
      "Requirement already satisfied: numpy in /Users/ruby/opt/anaconda3/lib/python3.8/site-packages (1.20.1)\n",
      "Requirement already satisfied: matplotlib in /Users/ruby/opt/anaconda3/lib/python3.8/site-packages (3.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/ruby/opt/anaconda3/lib/python3.8/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/ruby/opt/anaconda3/lib/python3.8/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/ruby/opt/anaconda3/lib/python3.8/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/ruby/opt/anaconda3/lib/python3.8/site-packages (from matplotlib) (8.2.0)\n",
      "Requirement already satisfied: numpy>=1.15 in /Users/ruby/opt/anaconda3/lib/python3.8/site-packages (from matplotlib) (1.20.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /Users/ruby/opt/anaconda3/lib/python3.8/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: six in /Users/ruby/opt/anaconda3/lib/python3.8/site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
      "Requirement already satisfied: opencv-python in /Users/ruby/opt/anaconda3/lib/python3.8/site-packages (4.5.5.64)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /Users/ruby/opt/anaconda3/lib/python3.8/site-packages (from opencv-python) (1.20.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install torch\n",
    "!pip install torchvision\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "N_XAZJXsgyY5",
   "metadata": {
    "id": "N_XAZJXsgyY5"
   },
   "source": [
    "## import & 버전 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "jEIP5rscg3ZD",
   "metadata": {
    "id": "jEIP5rscg3ZD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.8\n",
      "zsh:1: command not found: nvidia-smi\n",
      "1.11.0\n",
      "1.20.1\n",
      "0.12.0\n"
     ]
    }
   ],
   "source": [
    "!python --version\n",
    "!nvidia-smi\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "print(torch.__version__)\n",
    "print(np.__version__)\n",
    "print(torchvision.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4t53bdHUjmDC",
   "metadata": {
    "id": "4t53bdHUjmDC"
   },
   "source": [
    "## inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bduUNYwgjtE0",
   "metadata": {
    "id": "bduUNYwgjtE0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class ModelV3(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelV3, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = torch.nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = torch.nn.Dropout(0.25)\n",
    "        self.dropout2 = torch.nn.Dropout(0.5)\n",
    "        self.fc1 = torch.nn.Linear(9216, 128)\n",
    "        self.fc2 = torch.nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "class inference_model:\n",
    "    def __init__(self):\n",
    "        self.model = torch.load('../model.pt')\n",
    "        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        #self.imgs = np.load('../mnist_inputs.npy')\n",
    "\n",
    "    def inference(self, img):\n",
    "        self.model = self.model.to(self.device)\n",
    "        \n",
    "        img = torch.from_numpy(img).float() # torch.tensor(random).float() ? 뭔 차이? 둘다 type은 tenser\n",
    "        img = img.to(self.device)\n",
    "\n",
    "        self.model.eval()    #nn.Module에서 train time과 eval time에서 수행하는 다른 작업을 수행할 수 있도록 switching 하는 함수\n",
    "        with torch.no_grad():\n",
    "            out = self.model(img)\n",
    "            label_idx = torch.argmax(out, dim=1)\n",
    "        return label_idx\n",
    "    \n",
    "\"\"\"\n",
    "MNIST의 test data 중에서 0부터 9까지 각 1장씩, 총 10장을 랜덤으로 추출해서 \n",
    "[10, 28, 28]의 shape로 묶어서 numpy.array 형태로 저장해둔 파일\n",
    "len(imgdata) = 10, len(imgdata[0]) = 28\n",
    "\"\"\"\n",
    "\n",
    "# print(imgdata[1].shape) (28,28) \n",
    "\n",
    "imgdata = np.load('../mnist_inputs.npy')\n",
    "\n",
    "for i in range(len(imgdata)):\n",
    "    testimg = np.expand_dims(imgdata[i], axis=(0,1)) # (28,28) -> (1, 1, 28, 28) 튜플을 사용해서 차원 한꺼번에 추가\n",
    "    #print(testimg.shape)\n",
    "    infer = inference_model()\n",
    "    rst = infer.inference(testimg).item()\n",
    "    print(rst)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51c0b2f",
   "metadata": {},
   "source": [
    "## inference 2\n",
    "- img 입력을 init 에서 & 결과 출력하는 함수를 inference model class의 메소드로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2654e3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class ModelV3(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelV3, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = torch.nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = torch.nn.Dropout(0.25)\n",
    "        self.dropout2 = torch.nn.Dropout(0.5)\n",
    "        self.fc1 = torch.nn.Linear(9216, 128)\n",
    "        self.fc2 = torch.nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "class inference_model:\n",
    "    def __init__(self):\n",
    "        self.model = torch.load('../model.pt')\n",
    "        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        self.imgs = np.load('../mnist_inputs.npy')\n",
    "    \n",
    "    def printInference(self):\n",
    "        for i in range(len(self.imgs)):\n",
    "            testimg = np.expand_dims(imgdata[i], axis=0)\n",
    "            testimg = np.expand_dims(testimg, axis=0)\n",
    "            rst = self.inference(testimg)\n",
    "            print(rst.item())\n",
    "        return\n",
    "\n",
    "    def inference(self,img):\n",
    "        self.model = self.model.to(self.device)\n",
    "        \n",
    "        img = torch.from_numpy(img).float()\n",
    "        img = img.to(self.device)\n",
    "\n",
    "        self.model.eval()    \n",
    "        with torch.no_grad():\n",
    "            out = self.model(img)\n",
    "            label_idx = torch.argmax(out, dim=1)\n",
    "        return label_idx\n",
    "    \n",
    "\n",
    "imgdata = np.load('../mnist_inputs.npy')\n",
    "\n",
    "\n",
    "infer = inference_model()\n",
    "infer.printInference()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "training_remind_seminar.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
